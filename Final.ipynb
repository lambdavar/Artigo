{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184afbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precisa ter o tesnroflow versao 2.10 no máximo pq tiraram suporte de GPU no windows por algum motivo\n",
    "#!conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "#!pip install --upgrade pip\n",
    "#!pip install \"tensorflow<2.11\"\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "741025f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import wget\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from timeit import default_timer as timer\n",
    "from pyts.image import GramianAngularField\n",
    "from pyts.image import MarkovTransitionField\n",
    "from keras.utils import load_img\n",
    "from keras.utils import save_img\n",
    "from keras.utils import img_to_array\n",
    "from keras.utils import array_to_img\n",
    "from keras.regularizers import l2\n",
    "import funcoes as f\n",
    "import asyncio\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from joblib import dump, load\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "tf.get_logger().setLevel('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555ae19",
   "metadata": {},
   "source": [
    "Testa se está funcionando com GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d27cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd4db344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define o ticker do ativo que vou usar pra treinar o modelo\n",
    "ticker = \"BTCUSDT\"\n",
    "# timeframes precisa estar em ordem crescente e começar em 1s ou 1m\n",
    "timeframes = (\"1m\", \"5m\", \"15m\", \"30m\", \"1h\", \"2h\", \"4h\", \"8h\", \"1d\")\n",
    "# quantos períodos vamos olhar pro passado\n",
    "lookback = 20\n",
    "# numero de quantis pra usar no markov transition field. Precisa tunar.\n",
    "quantis = 3\n",
    "# pega número de timeframes por minuto ou segundo\n",
    "timeframes_padronizado = tuple(f.timeframes_mesma_unidade(timeframes))\n",
    "# tamanho das batches de treinamento. Tem mais a ver com velocidade de processamento e não interfere muito nos resultados\n",
    "batch_size = 1024#512\n",
    "# set seed pros resultados não variarem\n",
    "seed = 777\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# pega tamanho da imagem (input)\n",
    "img_shape = f.image_shape()\n",
    "# porcentagem dos dados que vou usar pra treino e teste\n",
    "pct_imagens_teste = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e299f35",
   "metadata": {},
   "source": [
    "# Prepara os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b264389",
   "metadata": {},
   "source": [
    "### Baixa e corrige dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392422bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixa os dados e junta cada timeframe e junta em 1 csv por timeframe\n",
    "# retorna None se arquivo processado já existe e timeframe se ele criou um arquivo do 0\n",
    "lista_processados = []\n",
    "for timeframe in timeframes:\n",
    "    lista_processados.append(f.baixa_e_concatena(ticker= ticker, timeframe=timeframe, ano_inicial=2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insere linhas sem dados e preenche com 0\n",
    "# só corrige os timeframes que foram processados anteriormente\n",
    "lista_p_correcao = [item for item in lista_processados if item != None]\n",
    "f.corrige_arquivos(lista_p_correcao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f065f9",
   "metadata": {},
   "source": [
    "### Cria janelas, GAF's e salva imagens\n",
    "Imagens ficam localizadas na pasta dados e são separadas por clissificação de compra ou venda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e36620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria uma lista de numpy arrays com os dados de cada timeframe.\n",
    "# Eles estão organizados na mesma ordem que os timeframes\n",
    "dfs_close = [(pd.read_csv(f\"./Dados/Processados/BTCUSDT-{timeframe}.csv\", \n",
    "                      usecols=[\"Close time\", \"Close\"])[::-1][[\"Close\", \"Close time\"]]).to_numpy(dtype=\"float32\") for timeframe in timeframes]\n",
    "dfs_close = tuple(dfs_close)\n",
    "\n",
    "# faz a mesma coisa pros dados de volume\n",
    "dfs_volume = [(pd.read_csv(f\"./Dados/Processados/BTCUSDT-{timeframe}.csv\", \n",
    "                      usecols=[\"Close time\", \"Volume\"])[::-1][[\"Volume\", \"Close time\"]]).to_numpy(dtype=\"float32\") for timeframe in timeframes]\n",
    "dfs_volume = tuple(dfs_volume)\n",
    "\n",
    "dfs_close[0], dfs_volume[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea460673",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ultima_linha = len(dfs_close[0])-(lookback*timeframes_padronizado[-1])\n",
    "    print(\"qtd de imagens para treino\", ultima_linha-int(ultima_linha*pct_imagens_teste))\n",
    "    print(\"qtd de imagens para teste\", int(ultima_linha*pct_imagens_teste))\n",
    "    # linhas de teste são as primeiras x%, pois os dados mais recentes vem antes\n",
    "    # linhas de treino são as restantes\n",
    "    linhas_teste = range(0, int(ultima_linha*pct_imagens_teste))\n",
    "    linhas_treino = range(int(ultima_linha*pct_imagens_teste)+1, ultima_linha+1)\n",
    "    \n",
    "    # cria imagens usando multithreading\n",
    "    f.roda_paralelo(linhas_treino, linhas_teste, dfs_close, dfs_volume, lookback, quantis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9b8b7",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ba271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN com hinge loss e regularizador, se aproximando de uma SVM\n",
    "def CNN_hinge(img_shape=img_shape):\n",
    "    # define our MLP network\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Input(shape=(20, 180, 3)))\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    \n",
    "    # reescala os dados pra entre 0 e 1\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    \n",
    "    # classificação\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(layers.Dense(16, activation=\"linear\"))\n",
    "    model.add(layers.Dense(8, activation=\"linear\"))\n",
    "    model.add(layers.Dense(1, kernel_regularizer=l2(0.01)))\n",
    "    model.add(layers.Activation('linear'))\n",
    "    \n",
    "    model.compile(loss = \"categorical_hinge\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                             keras.metrics.Precision(),\n",
    "                                                             keras.metrics.Recall(), \n",
    "                                                             keras.metrics.AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abefe034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rede CNN padrão\n",
    "def CNN(img_shape=img_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    \n",
    "    # reescala os dados pra entre 0 e 1\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    \n",
    "    # classificação\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(layers.Dense(16, activation=\"linear\"))\n",
    "    model.add(layers.Dense(8, activation=\"linear\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f4aaf",
   "metadata": {},
   "source": [
    "# Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modelos=5\n",
    "modelos = [CNN_hinge() for i in range(n_modelos)]\n",
    "resultado_CNN_hinge = np.empty((n_modelos, 5))\n",
    "repeticao = 0\n",
    "for model in modelos:\n",
    "    # precisa definir o checkpoint antes de começar cada CNN. Se não acaba usando um do outro\n",
    "    checkpoint = ModelCheckpoint(\"modelo\", monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "    # para de treinar se a acuracia de treino parar de aumentar por 3 epochs\n",
    "    es = EarlyStopping(monitor='accuracy', patience=4)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "\n",
    "    # treina CNN hinge\n",
    "    model = CNN_hinge()\n",
    "    #model.compile(loss = \"categorical_hinge\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "    #                                                                 keras.metrics.Precision(),\n",
    "    #                                                                 keras.metrics.Recall(), \n",
    "    #                                                                 keras.metrics.AUC()])\n",
    "    model.fit(train_data,  epochs=25, use_multiprocessing=True, verbose=0, callbacks=callbacks_list)\n",
    "    model = keras.models.load_model(\"modelo\")\n",
    "    resultado_CNN_hinge[repeticao] = model.evaluate(validation_data)\n",
    "    repeticao = repeticao + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c72cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma resultados CNN em df e tira a loss\n",
    "resultado_CNN_hinge = pd.DataFrame(resultado_CNN_hinge, columns=[\"loss\", \"accuracy\", \"precision\", \"recall\", \"AUC\"]).drop(columns=[\"loss\"])\n",
    "# calcula f1\n",
    "resultado_CNN_hinge[\"f1-score\"] = 2*(resultado_CNN_hinge[\"precision\"]*resultado_CNN_hinge[\"recall\"])/(resultado_CNN_hinge[\"precision\"]+resultado_CNN_hinge[\"recall\"])\n",
    "# poe 0 nos nans\n",
    "resultado_CNN_hinge.fillna(0, inplace=True)\n",
    "# reordena as colunas\n",
    "colunas = [\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"]\n",
    "resultado_CNN_hinge = resultado_CNN_hinge[colunas]\n",
    "display(resultado_CNN_hinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2714beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz votacao dos resultados. depois repete pro CNN normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels with models\n",
    "labels = []\n",
    "for m in models:\n",
    "    predicts = np.argmax(m.predict(test), axis=1)\n",
    "    labels.append(predicts)\n",
    "    \n",
    "# Ensemble with voting\n",
    "labels = np.array(labels)\n",
    "labels = np.transpose(labels, (1, 0))\n",
    "labels = scipy.stats.mode(labels, axis=-1)[0]\n",
    "labels = np.squeeze(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f121e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import wget\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import funcoes as f\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import absl.logging\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "tf.get_logger().setLevel('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32b3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"dp03\" # \"dp1\" , \"dp3\" ou \"dp03\"\n",
    "seed = np.random.randint(0, 9999)\n",
    "batch_size = 32\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89922ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dataset == \"dp3\":\n",
    "    img = load_img('./teste sanidade/dp3/DP3_class0/image1.png')\n",
    "elif dataset == \"dp1\":\n",
    "    img = load_img('./teste sanidade/dp1/DP1_class0/image1.png')\n",
    "elif dataset == \"dp03\":\n",
    "    img = load_img('./teste sanidade/dp03/classe1/image1.png')\n",
    "img = img_to_array(img)\n",
    "img_shape = img.shape\n",
    "del img\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a454ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d01627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 3\n"
     ]
    }
   ],
   "source": [
    "# pega 300 elementos do dataset para treino e 100 pra validação\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "train_data = dados.take((n_samples//batch_size))\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "validation_data = dados.take((100//batch_size))\n",
    "print(len(train_data), len(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a7d3b",
   "metadata": {},
   "source": [
    "# CNN hinge loss e regularizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd560f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## modelo csvm direto no keras\n",
    "\n",
    "def CNN_hinge(img_shape=img_shape):\n",
    "    # define our MLP network\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Input(shape=(20, 180, 3)))\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    \n",
    "    # reescala os dados pra entre 0 e 1\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # primeira convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    \n",
    "    # segunda convolucao\n",
    "    #model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))#, padding=\"same\"))\n",
    "    #model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    #model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    #model.add(layers.Dropout(0.20))\n",
    "    \n",
    "    # terceira\n",
    "    #model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    #model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    #model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # FC_1024\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(layers.Dense(8, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, kernel_regularizer=l2(0.01))) # aqui mandam usar l2 0,01\n",
    "    model.add(layers.Activation('linear')) # aqui mandam por linear\n",
    "    #model.add(layers.Activation('relu')) # tentar com tanh \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd53bc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "31/31 [==============================] - 2s 5ms/step - loss: 1.2002 - accuracy: 0.5060 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4962\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0176 - accuracy: 0.5020 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5263\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.9938 - accuracy: 0.5061 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4932\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0184 - accuracy: 0.4990 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0188 - accuracy: 0.5232 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4824\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0181 - accuracy: 0.5184 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4875\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.0175 - accuracy: 0.5051 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0171 - accuracy: 0.5151 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0171 - accuracy: 0.4899 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0170 - accuracy: 0.4775 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0163 - accuracy: 0.4798 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0161 - accuracy: 0.4877 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4707\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0163 - accuracy: 0.5143 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4767\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0158 - accuracy: 0.4990 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 15/25\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0156 - accuracy: 0.5071 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 16/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0154 - accuracy: 0.5225 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4857\n",
      "Epoch 17/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0150 - accuracy: 0.4877 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 18/25\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.0147 - accuracy: 0.4889 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 19/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0145 - accuracy: 0.4918 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4847\n",
      "Epoch 20/25\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0140 - accuracy: 0.4867 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 21/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0139 - accuracy: 0.4918 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4780\n",
      "Epoch 22/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0140 - accuracy: 0.5020 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 23/25\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0138 - accuracy: 0.5041 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 24/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0127 - accuracy: 0.4788 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4938\n",
      "Epoch 25/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.0123 - accuracy: 0.4805 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0163 - accuracy: 0.5625 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0162702798843384, 0.5625, 0.0, 0.0, 0.5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## modelo cnn-svm direto no keras\n",
    "\n",
    "model = CNN_hinge()\n",
    "model.compile(loss = \"categorical_hinge\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "\n",
    "# callbacks\n",
    "# salva o melhor modelo na pasta \"modelo\"\n",
    "checkpoint = ModelCheckpoint(\"modelo\", monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "# para de treinar se a acuracia de treino parar de aumentar por 3 epochs\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "callbacks_list = [checkpoint, es]\n",
    "\n",
    "#treina\n",
    "history = model.fit(train_data,  epochs=25, use_multiprocessing=True)#, validation_data=validation_data)#, callbacks=callbacks_list )\n",
    "\n",
    "# carrega o melhor modelo treinado e avalia\n",
    "#model = keras.models.load_model(\"modelo\")\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d503eb8",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf78fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(img_shape=img_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    \n",
    "    # reescala os dados pra entre 0 e 1\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    \n",
    "    # classificação\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(layers.Dense(16, activation=\"relu\"))\n",
    "    model.add(layers.Dense(8, activation=\"relu\"))\n",
    "    # pra classificacao binaria parece que precisa usar sigmoid\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620b3253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "31/31 [==============================] - 1s 5ms/step - loss: 0.7421 - accuracy: 0.4768 - precision_1: 0.4811 - recall_1: 0.4571 - auc_1: 0.4777\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.5133 - precision_1: 0.5082 - recall_1: 0.7598 - auc_1: 0.5673\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.5827 - precision_1: 0.5669 - recall_1: 0.5975 - auc_1: 0.6429\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.6169 - precision_1: 0.6020 - recall_1: 0.7217 - auc_1: 0.6872\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.7244 - precision_1: 0.7065 - recall_1: 0.7378 - auc_1: 0.8491\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6066 - accuracy: 0.6465 - precision_1: 0.6365 - recall_1: 0.7194 - auc_1: 0.7320\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.8637 - precision_1: 0.8737 - recall_1: 0.8504 - auc_1: 0.9630\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8965 - precision_1: 0.8740 - recall_1: 0.9200 - auc_1: 0.9620\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3216 - accuracy: 0.9204 - precision_1: 0.9109 - recall_1: 0.9344 - auc_1: 0.9731\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.2425 - accuracy: 0.9476 - precision_1: 0.9377 - recall_1: 0.9602 - auc_1: 0.9942\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.1634 - accuracy: 0.9990 - precision_1: 0.9980 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.9877 - precision_1: 0.9956 - recall_1: 0.9785 - auc_1: 0.9995\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 15/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 16/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 17/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 18/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 19/25\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 20/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 21/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 22/25\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0104 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 23/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 24/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "Epoch 25/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - auc_1: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005977926775813103, 1.0, 1.0, 1.0, 0.9999999403953552]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "\n",
    "# callbacks\n",
    "# salva o melhor modelo na pasta \"modelo\"\n",
    "checkpoint = ModelCheckpoint(\"modelo\", monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "# para de treinar se a acuracia de treino parar de aumentar por 3 epochs\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "callbacks_list = [checkpoint, es]\n",
    "\n",
    "#treina\n",
    "history = model.fit(train_data,  epochs=25, use_multiprocessing=True)#, validation_data=validation_data)#, callbacks=callbacks_list )\n",
    "\n",
    "# carrega o melhor modelo treinado e avalia\n",
    "#model = keras.models.load_model(\"modelo\")\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607850b",
   "metadata": {},
   "source": [
    "# CSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601cc02",
   "metadata": {},
   "source": [
    "Aqui preciso declarar os dados novamente com batch_size=1 pra poder extrair os dados mais facilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ec1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSVM(img_shape=img_shape):\n",
    "    # define our MLP network\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Input(shape=(20, 180, 3)))\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # primeira convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))#, padding=\"same\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f1f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=1,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d378b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992 96\n"
     ]
    }
   ],
   "source": [
    "# pega 300 elementos do dataset para treino e 100 pra validação\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "train_data = dados.take((n_samples//batch_size)*batch_size)\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "validation_data = dados.take((100//batch_size)*batch_size)\n",
    "print(len(train_data), len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50d10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 62, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 62, 31, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 61504)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CSVM(img_shape=img_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb26a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados\n",
      " 100 %          \n"
     ]
    }
   ],
   "source": [
    "# coloca os dados de treino da SVM em um numpy array\n",
    "\n",
    "predictions = np.empty(shape=(len(train_data), list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "labels =  np.empty(len(train_data), dtype=\"int\").reshape(-1, 1)\n",
    "i = 0\n",
    "j = 0\n",
    "print(\"Preparando dados\")\n",
    "for x, y in train_data:\n",
    "    #print(y)\n",
    "    if i == j:\n",
    "        print(\"\\r\", round(j/len(train_data)*100, 1),\"%\", end=\"    \")\n",
    "        j += 1000\n",
    "    predictions[i] = (model(x, training=False).numpy()[0])\n",
    "    labels[i] = y.numpy()[0]\n",
    "    i += 1\n",
    "labels = np.ravel(labels)\n",
    "print(\"\\r\", \"100\", \"%\", \"         \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6afc7cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando modelo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medindo score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_svm = LinearSVC()\n",
    "print(\"treinando modelo\")\n",
    "modelo_svm.fit(predictions, labels)\n",
    "print(\"medindo score\")\n",
    "modelo_svm.score(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64e72a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados\n",
      " 100 %          \n"
     ]
    }
   ],
   "source": [
    "# dados de teste pro csvm\n",
    "predictions = np.empty(shape=(len(validation_data), list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "labels =  np.empty(len(validation_data), dtype=\"int\").reshape(-1, 1)\n",
    "i = 0\n",
    "j = 0\n",
    "print(\"Preparando dados\")\n",
    "for x, y in validation_data:\n",
    "    #print(y)\n",
    "    if i == j:\n",
    "        print(\"\\r\", round(j/len(validation_data)*100, 1),\"%\", end=\"    \")\n",
    "        j += 1000\n",
    "    predictions[i] = (model(x, training=False).numpy()[0])\n",
    "    labels[i] = y.numpy()[0]\n",
    "    i += 1\n",
    "labels = np.ravel(labels)\n",
    "print(\"\\r\", \"100\", \"%\", \"         \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e994ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testando modelo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"testando modelo\")\n",
    "modelo_svm.score(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdd430",
   "metadata": {},
   "source": [
    "## Treina multiplas vezes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e9a282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9792 - precision_2: 1.0000 - recall_2: 0.9574 - auc_2: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "1\n",
      "Found 2000 files belonging to 2 classes.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001AE3EA6B3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001AF452C6310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4479 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - auc_5: 0.5000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "2\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0033 - accuracy: 0.4688 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - auc_8: 0.5000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000 - precision_9: 1.0000 - recall_9: 1.0000 - auc_9: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "4\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0095 - accuracy: 0.5417 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - auc_10: 0.5000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "5\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.4479 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - auc_12: 0.9717\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "6\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - precision_15: 1.0000 - recall_15: 1.0000 - auc_15: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "7\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0061 - accuracy: 0.4896 - precision_16: 0.0000e+00 - recall_16: 0.0000e+00 - auc_16: 0.5000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 1.0000 - precision_17: 1.0000 - recall_17: 1.0000 - auc_17: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "8\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - precision_18: 1.0000 - recall_18: 1.0000 - auc_18: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4583 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00 - auc_19: 0.5000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "9\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - precision_20: 1.0000 - recall_20: 1.0000 - auc_20: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - precision_21: 1.0000 - recall_21: 1.0000 - auc_21: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "repeticoes = 10\n",
    "scores_CNN_hinge = []\n",
    "scores_CNN = []\n",
    "scores_CSVM = []\n",
    "resultado_linear = np.empty((repeticoes, 5))\n",
    "resultado_poli = np.empty((repeticoes, 5))\n",
    "resultado_rbf = np.empty((repeticoes, 5))\n",
    "resultado_CNN_hinge = np.empty((repeticoes, 5))\n",
    "resultado_CNN = np.empty((repeticoes, 5))\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "# treina n vezes e salva scores nos arrays\n",
    "for repeticao in range(repeticoes):\n",
    "    print(repeticao)\n",
    "    #cria dados\n",
    "    seed = np.random.randint(0, 9999)\n",
    "    dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)\n",
    "    \n",
    "    # pega 300 elementos do dataset para treino e 100 pra validação\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    train_data = dados.take((n_samples//batch_size))\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    validation_data = dados.take((100//batch_size))\n",
    "    \n",
    "    # treina CNN hinge\n",
    "    model = CNN_hinge()\n",
    "    model.compile(loss = \"categorical_hinge\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "    model.fit(train_data,  epochs=25, use_multiprocessing=True, verbose=0)#, validation_data=validation_data, verbose=0)#, callbacks=callbacks_list)\n",
    "    resultado_CNN_hinge[repeticao] = model.evaluate(validation_data)\n",
    "    del model\n",
    "    \n",
    "    # treina CNN normal\n",
    "    model = CNN()\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "    model.fit(train_data,  epochs=25, use_multiprocessing=True, verbose=0)#, validation_data=validation_data, verbose=0)#, callbacks=callbacks_list)\n",
    "    resultado_CNN[repeticao] = model.evaluate(validation_data)\n",
    "    del model\n",
    "    \n",
    "    # prepara os dados pra CSVM\n",
    "    dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=1,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)\n",
    "\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    train_data = dados.take((n_samples//batch_size)*batch_size)\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    validation_data = dados.take((100//batch_size)*batch_size)\n",
    "\n",
    "    model = CSVM(img_shape=img_shape)\n",
    "\n",
    "    # coloca os dados de treino da SVM em um numpy array\n",
    "\n",
    "    predictions = np.empty(shape=((n_samples//batch_size)*batch_size, list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "    labels =  np.empty((n_samples//batch_size)*batch_size, dtype=\"int\").reshape(-1, 1)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    #print(\"Preparando dados\")\n",
    "    for x, y in train_data:\n",
    "        #print(y)\n",
    "        if i == j:\n",
    "            #print(\"\\r\", round(j/((300//batch_size)*batch_size)*100, 1),\"%\", end=\"    \")\n",
    "            j += 1000\n",
    "        predictions[i] = (model(x, training=False).numpy()[0])\n",
    "        labels[i] = y.numpy()[0]\n",
    "        i += 1\n",
    "    labels = np.ravel(labels)\n",
    "    #print(\"\\r\", \"100\", \"%\", \"         \")\n",
    "    \n",
    "    \n",
    "     # treina CSVM\n",
    "    #modelo_svm = LinearSVC()\n",
    "    modelo_linear = SVC(kernel='linear')\n",
    "    modelo_poli = SVC(kernel='poly')\n",
    "    modelo_rbf = SVC(kernel='rbf')\n",
    "\n",
    "    modelo_linear.fit(predictions, labels)\n",
    "    modelo_poli.fit(predictions, labels)\n",
    "    modelo_rbf.fit(predictions, labels)\n",
    "    \n",
    "    # prepara dados de teste pro csvm\n",
    "    predictions = np.empty(shape=(((100//batch_size)*batch_size), list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "    labels =  np.empty(((100//batch_size)*batch_size), dtype=\"int\").reshape(-1, 1)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    #print(\"Preparando dados\")\n",
    "    for x, y in validation_data:\n",
    "        #print(y)\n",
    "        if i == j:\n",
    "            #print(\"\\r\", round(j/((100//batch_size)*batch_size)*100, 1),\"%\", end=\"    \")\n",
    "            j += 1000\n",
    "        predictions[i] = (model(x, training=False).numpy()[0])\n",
    "        labels[i] = y.numpy()[0]\n",
    "        i += 1\n",
    "    labels = np.ravel(labels)\n",
    "    #print(\"\\r\", \"100\", \"%\", \"         \")\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    y_pred = modelo_linear.predict(predictions)\n",
    "    y_true = labels\n",
    "    \n",
    "    resultado_linear[repeticao] = np.array([accuracy_score(y_true, y_pred),\n",
    "                   precision_score(y_true, y_pred), \n",
    "                   recall_score(y_true, y_pred), \n",
    "                   f1_score(y_true, y_pred),\n",
    "                   roc_auc_score(y_true, y_pred)\n",
    "                  ])\n",
    "    \n",
    "    y_pred = modelo_poli.predict(predictions)\n",
    "    y_true = labels\n",
    "    \n",
    "    resultado_poli[repeticao] = np.array([accuracy_score(y_true, y_pred),\n",
    "                   precision_score(y_true, y_pred), \n",
    "                   recall_score(y_true, y_pred), \n",
    "                   f1_score(y_true, y_pred),\n",
    "                   roc_auc_score(y_true, y_pred)\n",
    "                  ])\n",
    "    \n",
    "    y_pred = modelo_rbf.predict(predictions)\n",
    "    y_true = labels\n",
    "    \n",
    "    resultado_rbf[repeticao] = np.array([accuracy_score(y_true, y_pred),\n",
    "                   precision_score(y_true, y_pred), \n",
    "                   recall_score(y_true, y_pred), \n",
    "                   f1_score(y_true, y_pred),\n",
    "                   roc_auc_score(y_true, y_pred)\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5fe5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma resultados da SVM em df\n",
    "resultado_linear = pd.DataFrame(resultado_linear, columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"])\n",
    "resultado_poli = pd.DataFrame(resultado_poli, columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"])\n",
    "resultado_rbf = pd.DataFrame(resultado_rbf, columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"]) \n",
    "# transforma resultados CNN em df e tira a loss\n",
    "resultado_CNN = pd.DataFrame(resultado_CNN, columns=[\"loss\", \"accuracy\", \"precision\", \"recall\", \"AUC\"]).drop(columns=[\"loss\"])\n",
    "resultado_CNN_hinge = pd.DataFrame(resultado_CNN_hinge, columns=[\"loss\", \"accuracy\", \"precision\", \"recall\", \"AUC\"]).drop(columns=[\"loss\"])\n",
    "# calcula f1\n",
    "resultado_CNN[\"f1-score\"] = 2*(resultado_CNN[\"precision\"]*resultado_CNN[\"recall\"])/(resultado_CNN[\"precision\"]+resultado_CNN[\"recall\"])\n",
    "resultado_CNN_hinge[\"f1-score\"] = 2*(resultado_CNN_hinge[\"precision\"]*resultado_CNN_hinge[\"recall\"])/(resultado_CNN_hinge[\"precision\"]+resultado_CNN_hinge[\"recall\"])\n",
    "# poe 0 nos nans\n",
    "resultado_CNN.fillna(0, inplace=True)\n",
    "resultado_CNN_hinge.fillna(0, inplace=True)\n",
    "# reordena as colunas\n",
    "colunas = [\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"]\n",
    "resultado_CNN = resultado_CNN[colunas]\n",
    "resultado_CNN_hinge = resultado_CNN_hinge[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ed9838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall  f1-score       AUC\n",
       "0  0.979167        1.0  0.957447  0.978261  1.000000\n",
       "1  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "2  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "3  0.468750        0.0  0.000000  0.000000  0.500000\n",
       "4  0.541667        0.0  0.000000  0.000000  0.500000\n",
       "5  0.447917        0.0  0.000000  0.000000  0.971698\n",
       "6  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "7  0.489583        0.0  0.000000  0.000000  0.500000\n",
       "8  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "9  1.000000        1.0  1.000000  1.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision  recall  f1-score  AUC\n",
       "0  1.000000        1.0     1.0       1.0  1.0\n",
       "1  0.447917        0.0     0.0       0.0  0.5\n",
       "2  1.000000        1.0     1.0       1.0  1.0\n",
       "3  1.000000        1.0     1.0       1.0  1.0\n",
       "4  1.000000        1.0     1.0       1.0  1.0\n",
       "5  1.000000        1.0     1.0       1.0  1.0\n",
       "6  1.000000        1.0     1.0       1.0  1.0\n",
       "7  1.000000        1.0     1.0       1.0  1.0\n",
       "8  0.458333        0.0     0.0       0.0  0.5\n",
       "9  1.000000        1.0     1.0       1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision  recall  f1-score  AUC\n",
       "0       1.0        1.0     1.0       1.0  1.0\n",
       "1       1.0        1.0     1.0       1.0  1.0\n",
       "2       1.0        1.0     1.0       1.0  1.0\n",
       "3       1.0        1.0     1.0       1.0  1.0\n",
       "4       1.0        1.0     1.0       1.0  1.0\n",
       "5       1.0        1.0     1.0       1.0  1.0\n",
       "6       1.0        1.0     1.0       1.0  1.0\n",
       "7       1.0        1.0     1.0       1.0  1.0\n",
       "8       1.0        1.0     1.0       1.0  1.0\n",
       "9       1.0        1.0     1.0       1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision  recall  f1-score  AUC\n",
       "0       1.0        1.0     1.0       1.0  1.0\n",
       "1       1.0        1.0     1.0       1.0  1.0\n",
       "2       1.0        1.0     1.0       1.0  1.0\n",
       "3       1.0        1.0     1.0       1.0  1.0\n",
       "4       1.0        1.0     1.0       1.0  1.0\n",
       "5       1.0        1.0     1.0       1.0  1.0\n",
       "6       1.0        1.0     1.0       1.0  1.0\n",
       "7       1.0        1.0     1.0       1.0  1.0\n",
       "8       1.0        1.0     1.0       1.0  1.0\n",
       "9       1.0        1.0     1.0       1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.697917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.726415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.923913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.656863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.921569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall  f1-score       AUC\n",
       "0  0.770833   0.685714  1.000000  0.813559  0.770833\n",
       "1  0.697917   1.000000  0.452830  0.623377  0.726415\n",
       "2  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "3  0.927083   1.000000  0.847826  0.917647  0.923913\n",
       "4  0.635417   0.562500  1.000000  0.720000  0.656863\n",
       "5  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "6  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "7  0.531250   0.531250  1.000000  0.693878  0.500000\n",
       "8  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "9  0.916667   1.000000  0.843137  0.914894  0.921569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(resultado_CNN_hinge)\n",
    "display(resultado_CNN)\n",
    "display(resultado_linear)\n",
    "display(resultado_poli)\n",
    "display(resultado_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceb929be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN hinge</th>\n",
       "      <td>0.792708</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.847170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC linear</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC poli</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC rbf</th>\n",
       "      <td>0.847917</td>\n",
       "      <td>0.877946</td>\n",
       "      <td>0.914379</td>\n",
       "      <td>0.868335</td>\n",
       "      <td>0.849959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  precision    recall  f1-score       AUC\n",
       "CNN         0.890625   0.800000  0.800000  0.800000  0.900000\n",
       "CNN hinge   0.792708   0.600000  0.595745  0.597826  0.847170\n",
       "SVC linear  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "SVC poli    1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "SVC rbf     0.847917   0.877946  0.914379  0.868335  0.849959"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_finais = pd.DataFrame(columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"])\n",
    "resultados_finais.loc[\"CNN\"] = resultado_CNN.mean()\n",
    "resultados_finais.loc[\"CNN hinge\"] = resultado_CNN_hinge.mean()\n",
    "resultados_finais.loc[\"SVC linear\"] = resultado_linear.mean()\n",
    "resultados_finais.loc[\"SVC poli\"] = resultado_poli.mean()\n",
    "resultados_finais.loc[\"SVC rbf\"] = resultado_rbf.mean()\n",
    "resultados_finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

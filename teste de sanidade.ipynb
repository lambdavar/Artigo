{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f121e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import wget\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import funcoes as f\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import absl.logging\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "tf.get_logger().setLevel('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32b3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"dp03\" # \"dp1\" , \"dp3\" ou \"dp03\"\n",
    "seed = np.random.randint(0, 9999)\n",
    "batch_size = 32\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89922ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dataset == \"dp3\":\n",
    "    img = load_img('./teste sanidade/dp3/DP3_class0/image1.png')\n",
    "elif dataset == \"dp1\":\n",
    "    img = load_img('./teste sanidade/dp1/DP1_class0/image1.png')\n",
    "elif dataset == \"dp03\":\n",
    "    img = load_img('./teste sanidade/dp03/classe1/image1.png')\n",
    "img = img_to_array(img)\n",
    "img_shape = img.shape\n",
    "del img\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a454ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9d01627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 3\n"
     ]
    }
   ],
   "source": [
    "# pega 300 elementos do dataset para treino e 100 pra validação\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "train_data = dados.take((n_samples//batch_size))\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "validation_data = dados.take((100//batch_size))\n",
    "print(len(train_data), len(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a7d3b",
   "metadata": {},
   "source": [
    "# CNN hinge loss e regularizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd560f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## modelo csvm direto no keras\n",
    "\n",
    "def CNN_hinge(img_shape=img_shape):\n",
    "    # define our MLP network\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Input(shape=(20, 180, 3)))\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    \n",
    "    # reescala os dados pra entre 0 e 1\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # primeira convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    \n",
    "    # segunda convolucao\n",
    "    #model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))#, padding=\"same\"))\n",
    "    #model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    #model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    #model.add(layers.Dropout(0.20))\n",
    "    \n",
    "    # terceira\n",
    "    #model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    #model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "    #model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # FC_1024\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(layers.Dense(16, activation=\"linear\"))#\"relu\")) # tirar o relu resolveu o problema de não convergir as vezes\n",
    "    model.add(layers.Dense(8, activation=\"linear\"))#\"relu\"))\n",
    "    model.add(layers.Dense(1, kernel_regularizer=l2(0.01))) # aqui mandam usar l2 0,01\n",
    "    model.add(layers.Activation('linear')) # aqui mandam por linear\n",
    "    #model.add(layers.Activation('relu')) # tentar com tanh \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd53bc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "31/31 [==============================] - 2s 36ms/step - loss: 2.0145 - accuracy: 0.5379 - precision_24: 0.5447 - recall_24: 0.4037 - auc_24: 0.5190\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.8813 - accuracy: 0.6532 - precision_24: 1.0000 - recall_24: 0.2758 - auc_24: 0.6575\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.4747 - accuracy: 0.8014 - precision_24: 0.9528 - recall_24: 0.6247 - auc_24: 0.8918\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8014 - precision_24: 0.9390 - recall_24: 0.6473 - auc_24: 0.8772\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.2205 - accuracy: 0.9032 - precision_24: 0.9791 - recall_24: 0.8287 - auc_24: 0.9807\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.0215 - accuracy: 1.0000 - precision_24: 1.0000 - recall_24: 1.0000 - auc_24: 1.0000\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0357 - accuracy: 0.9950 - precision_24: 1.0000 - recall_24: 0.9900 - auc_24: 1.0000\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 1.0000 - precision_24: 1.0000 - recall_24: 1.0000 - auc_24: 1.0000\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 1.0000 - precision_24: 1.0000 - recall_24: 1.0000 - auc_24: 1.0000\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 1.0000 - precision_24: 1.0000 - recall_24: 1.0000 - auc_24: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 1.0000 - precision_24: 1.0000 - recall_24: 1.0000 - auc_24: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01794295571744442, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## modelo cnn-svm direto no keras\n",
    "\n",
    "model = CNN_hinge()\n",
    "model.compile(loss = \"categorical_hinge\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "\n",
    "# callbacks\n",
    "# salva o melhor modelo na pasta \"modelo\"\n",
    "checkpoint = ModelCheckpoint(\"modelo\", monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "# para de treinar se a acuracia de treino parar de aumentar por 3 epochs\n",
    "es = EarlyStopping(monitor='accuracy', patience=4)\n",
    "callbacks_list = [checkpoint, es]\n",
    "\n",
    "#treina\n",
    "history = model.fit(train_data,  epochs=25, use_multiprocessing=True, callbacks=callbacks_list )\n",
    "\n",
    "# carrega o melhor modelo treinado e avalia\n",
    "model = keras.models.load_model(\"modelo\")\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d503eb8",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf78fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(img_shape=img_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    \n",
    "    # reescala os dados pra entre 0 e 1\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    \n",
    "    # classificação\n",
    "    model.add(layers.Flatten(name=\"flatten\"))\n",
    "    model.add(layers.Dense(16, activation=\"linear\"))#\"relu\"))\n",
    "    model.add(layers.Dense(8, activation=\"linear\"))#\"relu\"))\n",
    "    # pra classificacao binaria parece que precisa usar sigmoid\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "620b3253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "31/31 [==============================] - 2s 29ms/step - loss: 2.3655 - accuracy: 0.5348 - precision_25: 0.5163 - recall_25: 0.4411 - auc_25: 0.5230\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.6684 - accuracy: 0.6004 - precision_25: 0.5896 - recall_25: 0.6502 - auc_25: 0.6490\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.4244 - accuracy: 0.9314 - precision_25: 0.9658 - recall_25: 0.8986 - auc_25: 0.9862\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 0.2180 - accuracy: 0.9950 - precision_25: 0.9958 - recall_25: 0.9938 - auc_25: 0.9999\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.1430 - accuracy: 0.9949 - precision_25: 0.9939 - recall_25: 0.9959 - auc_25: 0.9999\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0810 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - auc_25: 1.0000\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - auc_25: 1.0000\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - auc_25: 1.0000\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - auc_25: 1.0000\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - auc_25: 1.0000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - auc_25: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06761527806520462, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "\n",
    "# callbacks\n",
    "# salva o melhor modelo na pasta \"modelo\"\n",
    "checkpoint = ModelCheckpoint(\"modelo\", monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "# para de treinar se a acuracia de treino parar de aumentar por 3 epochs\n",
    "es = EarlyStopping(monitor='accuracy', patience=4)\n",
    "callbacks_list = [checkpoint, es]\n",
    "\n",
    "#treina\n",
    "history = model.fit(train_data,  epochs=25, use_multiprocessing=True, callbacks=callbacks_list)\n",
    "\n",
    "# carrega o melhor modelo treinado e avalia\n",
    "model = keras.models.load_model(\"modelo\")\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607850b",
   "metadata": {},
   "source": [
    "# CSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601cc02",
   "metadata": {},
   "source": [
    "Aqui preciso declarar os dados novamente com batch_size=1 pra poder extrair os dados mais facilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ec1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSVM(img_shape=img_shape):\n",
    "    # define our MLP network\n",
    "    model = keras.Sequential()\n",
    "    #model.add(layers.Input(shape=(20, 180, 3)))\n",
    "    model.add(layers.Input(shape=img_shape))\n",
    "    model.add(layers.Rescaling(1./255))\n",
    "    \n",
    "    # primeira convolucao\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))#, padding=\"same\"))\n",
    "    #model.add(layers.MaxPool2D(pool_size=(1, 2)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.15))\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f1f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=1,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d378b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992 96\n"
     ]
    }
   ],
   "source": [
    "# pega 300 elementos do dataset para treino e 100 pra validação\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "train_data = dados.take((n_samples//batch_size)*batch_size)\n",
    "dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "validation_data = dados.take((100//batch_size)*batch_size)\n",
    "print(len(train_data), len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50d10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 30752)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CSVM(img_shape=img_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb26a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados\n",
      " 100 %          \n"
     ]
    }
   ],
   "source": [
    "# coloca os dados de treino da SVM em um numpy array\n",
    "\n",
    "predictions = np.empty(shape=(len(train_data), list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "labels =  np.empty(len(train_data), dtype=\"int\").reshape(-1, 1)\n",
    "i = 0\n",
    "j = 0\n",
    "print(\"Preparando dados\")\n",
    "for x, y in train_data:\n",
    "    #print(y)\n",
    "    if i == j:\n",
    "        print(\"\\r\", round(j/len(train_data)*100, 1),\"%\", end=\"    \")\n",
    "        j += 1000\n",
    "    predictions[i] = (model(x, training=False).numpy()[0])\n",
    "    labels[i] = y.numpy()[0]\n",
    "    i += 1\n",
    "labels = np.ravel(labels)\n",
    "print(\"\\r\", \"100\", \"%\", \"         \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5520443c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0009765625, 0.001953125, 0.00390625, 0.0078125, 0.015625, 0.03125, 0.0625]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = [2**x for x in range(-10,-3)]\n",
    "gamma\n",
    "# 0.001953125 melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af0e6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'gamma': 0.0078125}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pega melhores parametros pro kernel rbf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "modelo_svm=SVC()\n",
    "params = {\"C\":[0.1, 0.5, 1, 5, 10], \"gamma\": gamma}\n",
    "grid_search = GridSearchCV(modelo_svm, params, n_jobs=-1)\n",
    "grid_search.fit(predictions, labels)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6afc7cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando modelo\n",
      "medindo score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_svm = LinearSVC()\n",
    "#modleo_svm = SVC(kernel='rbf', gamma=1, C=0.01)\n",
    "print(\"treinando modelo\")\n",
    "modelo_svm.fit(predictions, labels)\n",
    "print(\"medindo score\")\n",
    "modelo_svm.score(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d64e72a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados\n",
      " 100 %          \n"
     ]
    }
   ],
   "source": [
    "# dados de teste pro csvm\n",
    "predictions = np.empty(shape=(len(validation_data), list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "labels =  np.empty(len(validation_data), dtype=\"int\").reshape(-1, 1)\n",
    "i = 0\n",
    "j = 0\n",
    "print(\"Preparando dados\")\n",
    "for x, y in validation_data:\n",
    "    #print(y)\n",
    "    if i == j:\n",
    "        print(\"\\r\", round(j/len(validation_data)*100, 1),\"%\", end=\"    \")\n",
    "        j += 1000\n",
    "    predictions[i] = (model(x, training=False).numpy()[0])\n",
    "    labels[i] = y.numpy()[0]\n",
    "    i += 1\n",
    "labels = np.ravel(labels)\n",
    "print(\"\\r\", \"100\", \"%\", \"         \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e994ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testando modelo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"testando modelo\")\n",
    "modelo_svm.score(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdd430",
   "metadata": {},
   "source": [
    "## Treina multiplas vezes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e9a282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.4375 - precision_1: 0.4375 - recall_1: 1.0000 - auc_1: 0.9365\n",
      "Found 2000 files belonging to 2 classes.\n",
      "1\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - auc_2: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 1.0000 - precision_3: 1.0000 - recall_3: 1.0000 - auc_3: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "2\n",
      "Found 2000 files belonging to 2 classes.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000199E1EA65E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000199E1EA65E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000 - precision_4: 1.0000 - recall_4: 1.0000 - auc_4: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000019AEDF97E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000019AEDF97E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1972 - accuracy: 1.0000 - precision_5: 1.0000 - recall_5: 1.0000 - auc_5: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 1.0000 - precision_6: 1.0000 - recall_6: 1.0000 - auc_6: 1.0000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 1.0000 - precision_7: 1.0000 - recall_7: 1.0000 - auc_7: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "4\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - precision_8: 1.0000 - recall_8: 1.0000 - auc_8: 1.0000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.5104 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - auc_9: 0.7547\n",
      "Found 2000 files belonging to 2 classes.\n",
      "5\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - precision_10: 1.0000 - recall_10: 1.0000 - auc_10: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 1.0000 - precision_11: 1.0000 - recall_11: 1.0000 - auc_11: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "6\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 1.0000 - precision_12: 1.0000 - recall_12: 1.0000 - auc_12: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 1.0000 - precision_13: 1.0000 - recall_13: 1.0000 - auc_13: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "7\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 1.0000 - precision_14: 1.0000 - recall_14: 1.0000 - auc_14: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 1.0000 - precision_15: 1.0000 - recall_15: 1.0000 - auc_15: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "8\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000 - precision_16: 1.0000 - recall_16: 1.0000 - auc_16: 1.0000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0791 - accuracy: 1.0000 - precision_17: 1.0000 - recall_17: 1.0000 - auc_17: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "9\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 1.0000 - precision_18: 1.0000 - recall_18: 1.0000 - auc_18: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 1.0000 - precision_19: 1.0000 - recall_19: 1.0000 - auc_19: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "10\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 1.0000 - precision_20: 1.0000 - recall_20: 1.0000 - auc_20: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 1.0000 - precision_21: 1.0000 - recall_21: 1.0000 - auc_21: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "11\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 1.0000 - precision_22: 1.0000 - recall_22: 1.0000 - auc_22: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 1.0000 - precision_23: 1.0000 - recall_23: 1.0000 - auc_23: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "12\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9629 - accuracy: 0.5208 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00 - auc_24: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 1.0000 - precision_25: 1.0000 - recall_25: 1.0000 - auc_25: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "13\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000 - precision_26: 1.0000 - recall_26: 1.0000 - auc_26: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 1.0000 - precision_27: 1.0000 - recall_27: 1.0000 - auc_27: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "14\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0568 - accuracy: 0.4583 - precision_28: 0.0000e+00 - recall_28: 0.0000e+00 - auc_28: 0.5000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - precision_29: 1.0000 - recall_29: 1.0000 - auc_29: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "15\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 1.0000 - precision_30: 1.0000 - recall_30: 1.0000 - auc_30: 1.0000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0355 - accuracy: 1.0000 - precision_31: 1.0000 - recall_31: 1.0000 - auc_31: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "16\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 1.0000 - precision_32: 1.0000 - recall_32: 1.0000 - auc_32: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 1.0000 - precision_33: 1.0000 - recall_33: 1.0000 - auc_33: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "17\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 1.0000 - precision_34: 1.0000 - recall_34: 1.0000 - auc_34: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 1.0000 - precision_35: 1.0000 - recall_35: 1.0000 - auc_35: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "18\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0296 - accuracy: 0.6146 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - auc_36: 0.7306\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0614 - accuracy: 1.0000 - precision_37: 1.0000 - recall_37: 1.0000 - auc_37: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "19\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 1.0000 - precision_38: 1.0000 - recall_38: 1.0000 - auc_38: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 1.0000 - precision_39: 1.0000 - recall_39: 1.0000 - auc_39: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "20\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000 - precision_40: 1.0000 - recall_40: 1.0000 - auc_40: 1.0000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 1.0000 - precision_41: 1.0000 - recall_41: 1.0000 - auc_41: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "21\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 1.0000 - precision_42: 1.0000 - recall_42: 1.0000 - auc_42: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 1.0000 - precision_43: 1.0000 - recall_43: 1.0000 - auc_43: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "22\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 1.0000 - precision_44: 1.0000 - recall_44: 1.0000 - auc_44: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 1.0000 - precision_45: 1.0000 - recall_45: 1.0000 - auc_45: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "23\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - precision_46: 1.0000 - recall_46: 1.0000 - auc_46: 1.0000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 1.0000 - precision_47: 1.0000 - recall_47: 1.0000 - auc_47: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "24\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0148 - accuracy: 0.5208 - precision_48: 0.0000e+00 - recall_48: 0.0000e+00 - auc_48: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 1.0000 - precision_49: 1.0000 - recall_49: 1.0000 - auc_49: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "25\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0769 - accuracy: 0.9479 - precision_50: 1.0000 - recall_50: 0.8958 - auc_50: 1.0000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0495 - accuracy: 1.0000 - precision_51: 1.0000 - recall_51: 1.0000 - auc_51: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "26\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 1.0000 - precision_52: 1.0000 - recall_52: 1.0000 - auc_52: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 1.0000 - precision_53: 1.0000 - recall_53: 1.0000 - auc_53: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "27\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 1.0000 - precision_54: 1.0000 - recall_54: 1.0000 - auc_54: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 1.0000 - precision_55: 1.0000 - recall_55: 1.0000 - auc_55: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "28\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000 - precision_56: 1.0000 - recall_56: 1.0000 - auc_56: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 1.0000 - precision_57: 1.0000 - recall_57: 1.0000 - auc_57: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "29\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 1.0000 - precision_58: 1.0000 - recall_58: 1.0000 - auc_58: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 1.0000 - precision_59: 1.0000 - recall_59: 1.0000 - auc_59: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "30\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 1.0000 - precision_60: 1.0000 - recall_60: 1.0000 - auc_60: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.4896 - precision_61: 0.4896 - recall_61: 1.0000 - auc_61: 0.3011\n",
      "Found 2000 files belonging to 2 classes.\n",
      "31\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 1.0000 - precision_62: 1.0000 - recall_62: 1.0000 - auc_62: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 1.0000 - precision_63: 1.0000 - recall_63: 1.0000 - auc_63: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "32\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000 - precision_64: 1.0000 - recall_64: 1.0000 - auc_64: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 1.0000 - precision_65: 1.0000 - recall_65: 1.0000 - auc_65: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "33\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 1.0000 - precision_66: 1.0000 - recall_66: 1.0000 - auc_66: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 1.0000 - precision_67: 1.0000 - recall_67: 1.0000 - auc_67: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "34\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 1.0000 - precision_68: 1.0000 - recall_68: 1.0000 - auc_68: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 1.0000 - precision_69: 1.0000 - recall_69: 1.0000 - auc_69: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "35\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000 - precision_70: 1.0000 - recall_70: 1.0000 - auc_70: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 1.0000 - precision_71: 1.0000 - recall_71: 1.0000 - auc_71: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "36\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 1.0000 - precision_72: 1.0000 - recall_72: 1.0000 - auc_72: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 1.0000 - precision_73: 1.0000 - recall_73: 1.0000 - auc_73: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "37\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 1.0000 - precision_74: 1.0000 - recall_74: 1.0000 - auc_74: 1.0000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0979 - accuracy: 1.0000 - precision_75: 1.0000 - recall_75: 1.0000 - auc_75: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "38\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000 - precision_76: 1.0000 - recall_76: 1.0000 - auc_76: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 1.0000 - precision_77: 1.0000 - recall_77: 1.0000 - auc_77: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "39\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 1.0000 - precision_78: 1.0000 - recall_78: 1.0000 - auc_78: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 1.0000 - precision_79: 1.0000 - recall_79: 1.0000 - auc_79: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "40\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 1.0000 - precision_80: 1.0000 - recall_80: 1.0000 - auc_80: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 1.0000 - precision_81: 1.0000 - recall_81: 1.0000 - auc_81: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "41\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - precision_82: 1.0000 - recall_82: 1.0000 - auc_82: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 1.0000 - precision_83: 1.0000 - recall_83: 1.0000 - auc_83: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "42\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000 - precision_84: 1.0000 - recall_84: 1.0000 - auc_84: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 1.0000 - precision_85: 1.0000 - recall_85: 1.0000 - auc_85: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "43\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 1.0000 - precision_86: 1.0000 - recall_86: 1.0000 - auc_86: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 1.0000 - precision_87: 1.0000 - recall_87: 1.0000 - auc_87: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "44\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 1.0000 - precision_88: 1.0000 - recall_88: 1.0000 - auc_88: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.9896 - precision_89: 1.0000 - recall_89: 0.9821 - auc_89: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "45\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000 - precision_90: 1.0000 - recall_90: 1.0000 - auc_90: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 1.0000 - precision_91: 1.0000 - recall_91: 1.0000 - auc_91: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 1.0000 - precision_92: 1.0000 - recall_92: 1.0000 - auc_92: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000 - precision_93: 1.0000 - recall_93: 1.0000 - auc_93: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "47\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - precision_94: 1.0000 - recall_94: 1.0000 - auc_94: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 1.0000 - precision_95: 1.0000 - recall_95: 1.0000 - auc_95: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "48\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 1.0000 - precision_96: 1.0000 - recall_96: 1.0000 - auc_96: 1.0000\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 1.0000 - precision_97: 1.0000 - recall_97: 1.0000 - auc_97: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n",
      "49\n",
      "Found 2000 files belonging to 2 classes.\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 1.0000 - precision_98: 1.0000 - recall_98: 1.0000 - auc_98: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 1.0000 - precision_99: 1.0000 - recall_99: 1.0000 - auc_99: 1.0000\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "repeticoes = 50\n",
    "n_samples = 1000\n",
    "\n",
    "scores_CNN_hinge = []\n",
    "scores_CNN = []\n",
    "scores_CSVM = []\n",
    "resultado_linear = np.empty((repeticoes, 5))\n",
    "resultado_poli = np.empty((repeticoes, 5))\n",
    "resultado_rbf = np.empty((repeticoes, 5))\n",
    "resultado_CNN_hinge = np.empty((repeticoes, 5))\n",
    "resultado_CNN = np.empty((repeticoes, 5))\n",
    "\n",
    "# treina n vezes e salva scores nos arrays\n",
    "for repeticao in range(repeticoes):\n",
    "    print(repeticao)\n",
    "    #cria dados\n",
    "    seed = np.random.randint(0, 9999)\n",
    "    \n",
    "    # precisa definir o checkpoint antes de começar cada CNN. Se não acaba usando um do outro\n",
    "    checkpoint = ModelCheckpoint(\"modelo\", monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "    # para de treinar se a acuracia de treino parar de aumentar por 3 epochs\n",
    "    es = EarlyStopping(monitor='accuracy', patience=4)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    \n",
    "    dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)\n",
    "    \n",
    "    # pega 300 elementos do dataset para treino e 100 pra validação\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    train_data = dados.take((n_samples//batch_size))\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    validation_data = dados.take((100//batch_size))\n",
    "    \n",
    "    # treina CNN hinge\n",
    "    model = CNN_hinge()\n",
    "    model.compile(loss = \"categorical_hinge\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "    model.fit(train_data,  epochs=25, use_multiprocessing=True, verbose=0, callbacks=callbacks_list)\n",
    "    model = keras.models.load_model(\"modelo\")\n",
    "    resultado_CNN_hinge[repeticao] = model.evaluate(validation_data)\n",
    "    del model\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\"modelo\", monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "    # para de treinar se a acuracia de treino parar de aumentar por 3 epochs\n",
    "    es = EarlyStopping(monitor='accuracy', patience=4)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    \n",
    "    # treina CNN normal\n",
    "    model = CNN()\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\",\n",
    "                                                                     keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall(), \n",
    "                                                                     keras.metrics.AUC()])\n",
    "    model.fit(train_data,  epochs=25, use_multiprocessing=True, verbose=0, callbacks=callbacks_list)\n",
    "    model = keras.models.load_model(\"modelo\")\n",
    "    resultado_CNN[repeticao] = model.evaluate(validation_data)\n",
    "    del model\n",
    "    \n",
    "    # prepara os dados pra CSVM\n",
    "    dados = image_dataset_from_directory(f\"./teste sanidade/{dataset}/\",\n",
    "                                                   label_mode=\"binary\",\n",
    "                                                  image_size=img_shape[:2],\n",
    "                                                  batch_size=1,\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=seed)\n",
    "\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    train_data = dados.take((n_samples//batch_size)*batch_size)\n",
    "    dados = dados.shuffle(len(dados), seed=seed, reshuffle_each_iteration=True)\n",
    "    validation_data = dados.take((100//batch_size)*batch_size)\n",
    "\n",
    "    model = CSVM(img_shape=img_shape)\n",
    "\n",
    "    # coloca os dados de treino da SVM em um numpy array\n",
    "\n",
    "    predictions = np.empty(shape=((n_samples//batch_size)*batch_size, list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "    labels =  np.empty((n_samples//batch_size)*batch_size, dtype=\"int\").reshape(-1, 1)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    #print(\"Preparando dados\")\n",
    "    for x, y in train_data:\n",
    "        #print(y)\n",
    "        if i == j:\n",
    "            #print(\"\\r\", round(j/((300//batch_size)*batch_size)*100, 1),\"%\", end=\"    \")\n",
    "            j += 1000\n",
    "        predictions[i] = (model(x, training=False).numpy()[0])\n",
    "        labels[i] = y.numpy()[0]\n",
    "        i += 1\n",
    "    labels = np.ravel(labels)\n",
    "    #print(\"\\r\", \"100\", \"%\", \"         \")\n",
    "    \n",
    "    \n",
    "     # treina CSVM\n",
    "    #modelo_svm = LinearSVC()\n",
    "    modelo_linear = SVC(kernel='linear')\n",
    "    modelo_poli = SVC(kernel='poly')\n",
    "    modelo_rbf = SVC(kernel='rbf', C=0.5, gamma=0.0078125)\n",
    "\n",
    "    modelo_linear.fit(predictions, labels)\n",
    "    modelo_poli.fit(predictions, labels)\n",
    "    modelo_rbf.fit(predictions, labels)\n",
    "    \n",
    "    # prepara dados de teste pro csvm\n",
    "    predictions = np.empty(shape=(((100//batch_size)*batch_size), list(model.output.shape)[1]), dtype=\"float16\")#, dtype=\"float32\")\n",
    "    labels =  np.empty(((100//batch_size)*batch_size), dtype=\"int\").reshape(-1, 1)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    #print(\"Preparando dados\")\n",
    "    for x, y in validation_data:\n",
    "        #print(y)\n",
    "        if i == j:\n",
    "            #print(\"\\r\", round(j/((100//batch_size)*batch_size)*100, 1),\"%\", end=\"    \")\n",
    "            j += 1000\n",
    "        predictions[i] = (model(x, training=False).numpy()[0])\n",
    "        labels[i] = y.numpy()[0]\n",
    "        i += 1\n",
    "    labels = np.ravel(labels)\n",
    "    #print(\"\\r\", \"100\", \"%\", \"         \")\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    y_pred = modelo_linear.predict(predictions)\n",
    "    y_true = labels\n",
    "    \n",
    "    resultado_linear[repeticao] = np.array([accuracy_score(y_true, y_pred),\n",
    "                   precision_score(y_true, y_pred), \n",
    "                   recall_score(y_true, y_pred), \n",
    "                   f1_score(y_true, y_pred),\n",
    "                   roc_auc_score(y_true, y_pred)\n",
    "                  ])\n",
    "    \n",
    "    y_pred = modelo_poli.predict(predictions)\n",
    "    y_true = labels\n",
    "    \n",
    "    resultado_poli[repeticao] = np.array([accuracy_score(y_true, y_pred),\n",
    "                   precision_score(y_true, y_pred), \n",
    "                   recall_score(y_true, y_pred), \n",
    "                   f1_score(y_true, y_pred),\n",
    "                   roc_auc_score(y_true, y_pred)\n",
    "                  ])\n",
    "    \n",
    "    y_pred = modelo_rbf.predict(predictions)\n",
    "    y_true = labels\n",
    "    \n",
    "    resultado_rbf[repeticao] = np.array([accuracy_score(y_true, y_pred),\n",
    "                   precision_score(y_true, y_pred), \n",
    "                   recall_score(y_true, y_pred), \n",
    "                   f1_score(y_true, y_pred),\n",
    "                   roc_auc_score(y_true, y_pred)\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5fe5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma resultados da SVM em df\n",
    "resultado_linear = pd.DataFrame(resultado_linear, columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"])\n",
    "resultado_poli = pd.DataFrame(resultado_poli, columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"])\n",
    "resultado_rbf = pd.DataFrame(resultado_rbf, columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"]) \n",
    "# transforma resultados CNN em df e tira a loss\n",
    "resultado_CNN = pd.DataFrame(resultado_CNN, columns=[\"loss\", \"accuracy\", \"precision\", \"recall\", \"AUC\"]).drop(columns=[\"loss\"])\n",
    "resultado_CNN_hinge = pd.DataFrame(resultado_CNN_hinge, columns=[\"loss\", \"accuracy\", \"precision\", \"recall\", \"AUC\"]).drop(columns=[\"loss\"])\n",
    "# calcula f1\n",
    "resultado_CNN[\"f1-score\"] = 2*(resultado_CNN[\"precision\"]*resultado_CNN[\"recall\"])/(resultado_CNN[\"precision\"]+resultado_CNN[\"recall\"])\n",
    "resultado_CNN_hinge[\"f1-score\"] = 2*(resultado_CNN_hinge[\"precision\"]*resultado_CNN_hinge[\"recall\"])/(resultado_CNN_hinge[\"precision\"]+resultado_CNN_hinge[\"recall\"])\n",
    "# poe 0 nos nans\n",
    "resultado_CNN.fillna(0, inplace=True)\n",
    "resultado_CNN_hinge.fillna(0, inplace=True)\n",
    "# reordena as colunas\n",
    "colunas = [\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"]\n",
    "resultado_CNN = resultado_CNN[colunas]\n",
    "resultado_CNN_hinge = resultado_CNN_hinge[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66ed9838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.947917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall  f1-score       AUC\n",
       "0   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "1   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "2   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "3   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "4   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "5   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "6   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "7   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "8   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "9   1.000000        1.0  1.000000  1.000000  1.000000\n",
       "10  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "11  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "12  0.520833        0.0  0.000000  0.000000  0.500000\n",
       "13  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "14  0.458333        0.0  0.000000  0.000000  0.500000\n",
       "15  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "16  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "17  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "18  0.614583        0.0  0.000000  0.000000  0.730646\n",
       "19  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "20  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "21  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "22  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "23  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "24  0.520833        0.0  0.000000  0.000000  0.500000\n",
       "25  0.947917        1.0  0.895833  0.945055  1.000000\n",
       "26  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "27  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "28  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "29  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "30  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "31  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "32  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "33  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "34  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "35  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "36  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "37  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "38  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "39  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "40  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "41  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "42  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "43  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "44  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "45  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "46  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "47  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "48  1.000000        1.0  1.000000  1.000000  1.000000\n",
       "49  1.000000        1.0  1.000000  1.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>0.301129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.989583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall  f1-score       AUC\n",
       "0   0.437500   0.437500  1.000000  0.608696  0.936508\n",
       "1   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "2   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "3   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "4   0.510417   0.000000  0.000000  0.000000  0.754668\n",
       "5   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "6   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "7   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "8   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "9   1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "10  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "11  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "12  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "13  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "14  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "15  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "16  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "17  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "18  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "19  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "20  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "21  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "22  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "23  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "24  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "25  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "26  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "27  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "28  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "29  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "30  0.489583   0.489583  1.000000  0.657343  0.301129\n",
       "31  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "32  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "33  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "34  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "35  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "36  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "37  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "38  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "39  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "40  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "41  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "42  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "43  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "44  0.989583   1.000000  0.982143  0.990991  1.000000\n",
       "45  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "46  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "47  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "48  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "49  1.000000   1.000000  1.000000  1.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision  recall  f1-score  AUC\n",
       "0        1.0        1.0     1.0       1.0  1.0\n",
       "1        1.0        1.0     1.0       1.0  1.0\n",
       "2        1.0        1.0     1.0       1.0  1.0\n",
       "3        1.0        1.0     1.0       1.0  1.0\n",
       "4        1.0        1.0     1.0       1.0  1.0\n",
       "5        1.0        1.0     1.0       1.0  1.0\n",
       "6        1.0        1.0     1.0       1.0  1.0\n",
       "7        1.0        1.0     1.0       1.0  1.0\n",
       "8        1.0        1.0     1.0       1.0  1.0\n",
       "9        1.0        1.0     1.0       1.0  1.0\n",
       "10       1.0        1.0     1.0       1.0  1.0\n",
       "11       1.0        1.0     1.0       1.0  1.0\n",
       "12       1.0        1.0     1.0       1.0  1.0\n",
       "13       1.0        1.0     1.0       1.0  1.0\n",
       "14       1.0        1.0     1.0       1.0  1.0\n",
       "15       1.0        1.0     1.0       1.0  1.0\n",
       "16       1.0        1.0     1.0       1.0  1.0\n",
       "17       1.0        1.0     1.0       1.0  1.0\n",
       "18       1.0        1.0     1.0       1.0  1.0\n",
       "19       1.0        1.0     1.0       1.0  1.0\n",
       "20       1.0        1.0     1.0       1.0  1.0\n",
       "21       1.0        1.0     1.0       1.0  1.0\n",
       "22       1.0        1.0     1.0       1.0  1.0\n",
       "23       1.0        1.0     1.0       1.0  1.0\n",
       "24       1.0        1.0     1.0       1.0  1.0\n",
       "25       1.0        1.0     1.0       1.0  1.0\n",
       "26       1.0        1.0     1.0       1.0  1.0\n",
       "27       1.0        1.0     1.0       1.0  1.0\n",
       "28       1.0        1.0     1.0       1.0  1.0\n",
       "29       1.0        1.0     1.0       1.0  1.0\n",
       "30       1.0        1.0     1.0       1.0  1.0\n",
       "31       1.0        1.0     1.0       1.0  1.0\n",
       "32       1.0        1.0     1.0       1.0  1.0\n",
       "33       1.0        1.0     1.0       1.0  1.0\n",
       "34       1.0        1.0     1.0       1.0  1.0\n",
       "35       1.0        1.0     1.0       1.0  1.0\n",
       "36       1.0        1.0     1.0       1.0  1.0\n",
       "37       1.0        1.0     1.0       1.0  1.0\n",
       "38       1.0        1.0     1.0       1.0  1.0\n",
       "39       1.0        1.0     1.0       1.0  1.0\n",
       "40       1.0        1.0     1.0       1.0  1.0\n",
       "41       1.0        1.0     1.0       1.0  1.0\n",
       "42       1.0        1.0     1.0       1.0  1.0\n",
       "43       1.0        1.0     1.0       1.0  1.0\n",
       "44       1.0        1.0     1.0       1.0  1.0\n",
       "45       1.0        1.0     1.0       1.0  1.0\n",
       "46       1.0        1.0     1.0       1.0  1.0\n",
       "47       1.0        1.0     1.0       1.0  1.0\n",
       "48       1.0        1.0     1.0       1.0  1.0\n",
       "49       1.0        1.0     1.0       1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision  recall  f1-score  AUC\n",
       "0        1.0        1.0     1.0       1.0  1.0\n",
       "1        1.0        1.0     1.0       1.0  1.0\n",
       "2        1.0        1.0     1.0       1.0  1.0\n",
       "3        1.0        1.0     1.0       1.0  1.0\n",
       "4        1.0        1.0     1.0       1.0  1.0\n",
       "5        1.0        1.0     1.0       1.0  1.0\n",
       "6        1.0        1.0     1.0       1.0  1.0\n",
       "7        1.0        1.0     1.0       1.0  1.0\n",
       "8        1.0        1.0     1.0       1.0  1.0\n",
       "9        1.0        1.0     1.0       1.0  1.0\n",
       "10       1.0        1.0     1.0       1.0  1.0\n",
       "11       1.0        1.0     1.0       1.0  1.0\n",
       "12       1.0        1.0     1.0       1.0  1.0\n",
       "13       1.0        1.0     1.0       1.0  1.0\n",
       "14       1.0        1.0     1.0       1.0  1.0\n",
       "15       1.0        1.0     1.0       1.0  1.0\n",
       "16       1.0        1.0     1.0       1.0  1.0\n",
       "17       1.0        1.0     1.0       1.0  1.0\n",
       "18       1.0        1.0     1.0       1.0  1.0\n",
       "19       1.0        1.0     1.0       1.0  1.0\n",
       "20       1.0        1.0     1.0       1.0  1.0\n",
       "21       1.0        1.0     1.0       1.0  1.0\n",
       "22       1.0        1.0     1.0       1.0  1.0\n",
       "23       1.0        1.0     1.0       1.0  1.0\n",
       "24       1.0        1.0     1.0       1.0  1.0\n",
       "25       1.0        1.0     1.0       1.0  1.0\n",
       "26       1.0        1.0     1.0       1.0  1.0\n",
       "27       1.0        1.0     1.0       1.0  1.0\n",
       "28       1.0        1.0     1.0       1.0  1.0\n",
       "29       1.0        1.0     1.0       1.0  1.0\n",
       "30       1.0        1.0     1.0       1.0  1.0\n",
       "31       1.0        1.0     1.0       1.0  1.0\n",
       "32       1.0        1.0     1.0       1.0  1.0\n",
       "33       1.0        1.0     1.0       1.0  1.0\n",
       "34       1.0        1.0     1.0       1.0  1.0\n",
       "35       1.0        1.0     1.0       1.0  1.0\n",
       "36       1.0        1.0     1.0       1.0  1.0\n",
       "37       1.0        1.0     1.0       1.0  1.0\n",
       "38       1.0        1.0     1.0       1.0  1.0\n",
       "39       1.0        1.0     1.0       1.0  1.0\n",
       "40       1.0        1.0     1.0       1.0  1.0\n",
       "41       1.0        1.0     1.0       1.0  1.0\n",
       "42       1.0        1.0     1.0       1.0  1.0\n",
       "43       1.0        1.0     1.0       1.0  1.0\n",
       "44       1.0        1.0     1.0       1.0  1.0\n",
       "45       1.0        1.0     1.0       1.0  1.0\n",
       "46       1.0        1.0     1.0       1.0  1.0\n",
       "47       1.0        1.0     1.0       1.0  1.0\n",
       "48       1.0        1.0     1.0       1.0  1.0\n",
       "49       1.0        1.0     1.0       1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.93750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall  f1-score       AUC\n",
       "0    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "1    0.84375        1.0  0.666667  0.800000  0.833333\n",
       "2    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "3    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "4    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "5    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "6    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "7    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "8    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "9    1.00000        1.0  1.000000  1.000000  1.000000\n",
       "10   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "11   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "12   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "13   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "14   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "15   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "16   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "17   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "18   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "19   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "20   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "21   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "22   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "23   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "24   0.93750        1.0  0.857143  0.923077  0.928571\n",
       "25   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "26   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "27   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "28   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "29   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "30   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "31   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "32   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "33   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "34   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "35   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "36   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "37   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "38   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "39   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "40   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "41   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "42   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "43   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "44   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "45   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "46   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "47   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "48   1.00000        1.0  1.000000  1.000000  1.000000\n",
       "49   1.00000        1.0  1.000000  1.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(resultado_CNN_hinge)\n",
    "display(resultado_CNN)\n",
    "display(resultado_linear)\n",
    "display(resultado_poli)\n",
    "display(resultado_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceb929be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.968542</td>\n",
       "      <td>0.958542</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>0.965141</td>\n",
       "      <td>0.979846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN hinge</th>\n",
       "      <td>0.961250</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.917917</td>\n",
       "      <td>0.918901</td>\n",
       "      <td>0.964613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSVM linear</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSVM poli</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSVM rbf</th>\n",
       "      <td>0.995625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.994462</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy  precision    recall  f1-score       AUC\n",
       "CNN          0.968542   0.958542  0.979643  0.965141  0.979846\n",
       "CNN hinge    0.961250   0.920000  0.917917  0.918901  0.964613\n",
       "CSVM linear  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "CSVM poli    1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "CSVM rbf     0.995625   1.000000  0.990476  0.994462  0.995238"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_finais = pd.DataFrame(columns=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"AUC\"])\n",
    "resultados_finais.loc[\"CNN\"] = resultado_CNN.mean()\n",
    "resultados_finais.loc[\"CNN hinge\"] = resultado_CNN_hinge.mean()\n",
    "resultados_finais.loc[\"CSVM linear\"] = resultado_linear.mean()\n",
    "resultados_finais.loc[\"CSVM poli\"] = resultado_poli.mean()\n",
    "resultados_finais.loc[\"CSVM rbf\"] = resultado_rbf.mean()\n",
    "resultados_finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a81bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_finais.to_excel(f\"Resultado teste sanidade {n_samples} samples {repeticoes} repeticoes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309ae90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
